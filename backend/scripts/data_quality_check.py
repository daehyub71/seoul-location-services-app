"""
ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (Day 6)
Supabaseì— ì €ì¥ëœ ë°ì´í„°ì˜ í’ˆì§ˆ ê²€ì¦
"""

import sys
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime
import os

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from supabase import create_client, Client
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')

if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError("SUPABASE_URL and SUPABASE_KEY must be set in .env")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)


# ì„œìš¸ì‹œ ì¢Œí‘œ ë²”ìœ„ (WGS84)
SEOUL_BOUNDS = {
    'lat_min': 37.413,  # ë‚¨ë‹¨
    'lat_max': 37.715,  # ë¶ë‹¨
    'lon_min': 126.734,  # ì„œë‹¨
    'lon_max': 127.269   # ë™ë‹¨
}


class DataQualityChecker:
    """
    ë°ì´í„° í’ˆì§ˆ ê²€ì¦ê¸°

    ê²€ì¦ í•­ëª©:
    1. ì¢Œí‘œ ë²”ìœ„ ê²€ì¦ (ì„œìš¸ì‹œ ë‚´)
    2. ì¤‘ë³µ ë ˆì½”ë“œ ì²´í¬
    3. ëˆ„ë½ í•„ë“œ ì²´í¬
    4. ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦
    """

    def __init__(self):
        self.tables = [
            'cultural_events',
            'libraries',
            'cultural_spaces',
            'future_heritages',
            'public_reservations'
        ]

        self.issues: List[Dict[str, Any]] = []

    def check_all(self) -> Dict[str, Any]:
        """ì „ì²´ í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰"""
        print("\n" + "="*70)
        print("ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œì‘")
        print("="*70)
        print(f"ê²€ì¦ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ê²€ì¦ í…Œì´ë¸”: {len(self.tables)}ê°œ")
        print("="*70 + "\n")

        for table in self.tables:
            print(f"\nğŸ“Š [{table}] ê²€ì¦ ì¤‘...")
            print("-" * 70)

            try:
                # í…Œì´ë¸” í†µê³„
                self._check_table_stats(table)

                # ì¢Œí‘œ ë²”ìœ„ ê²€ì¦
                self._check_coordinate_bounds(table)

                # ì¤‘ë³µ ë ˆì½”ë“œ ê²€ì¦
                self._check_duplicates(table)

                # í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ê²€ì¦
                self._check_missing_fields(table)

                print(f"âœ… [{table}] ê²€ì¦ ì™„ë£Œ")

            except Exception as e:
                print(f"âŒ [{table}] ê²€ì¦ ì‹¤íŒ¨: {e}")
                self.issues.append({
                    'table': table,
                    'type': 'error',
                    'message': str(e)
                })

        # ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥
        self._print_report()

        return {
            'issues': self.issues,
            'total_issues': len(self.issues)
        }

    def _check_table_stats(self, table: str):
        """í…Œì´ë¸” ê¸°ë³¸ í†µê³„"""
        try:
            response = supabase.table(table).select('*', count='exact').execute()
            count = response.count

            print(f"  ì´ ë ˆì½”ë“œ: {count:,}ê°œ")

        except Exception as e:
            print(f"  âš ï¸  í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    def _check_coordinate_bounds(self, table: str):
        """ì¢Œí‘œ ë²”ìœ„ ê²€ì¦ (ì„œìš¸ì‹œ ë‚´)"""

        # í…Œì´ë¸”ë³„ ì¢Œí‘œ ì»¬ëŸ¼ëª… ë§¤í•‘
        coord_columns = {
            'cultural_events': ('latitude', 'longitude'),
            'libraries': ('latitude', 'longitude'),
            'cultural_spaces': ('latitude', 'longitude'),
            'future_heritages': ('latitude', 'longitude'),
            'public_reservations': ('y_coord', 'x_coord')  # y=lat, x=lon
        }

        if table not in coord_columns:
            print(f"  âš ï¸  ì¢Œí‘œ ì»¬ëŸ¼ ì •ë³´ ì—†ìŒ")
            return

        lat_col, lon_col = coord_columns[table]

        try:
            # ì¢Œí‘œê°€ ìˆëŠ” ë ˆì½”ë“œë§Œ ì¡°íšŒ
            response = supabase.table(table).select(
                f'api_id,{lat_col},{lon_col}'
            ).not_.is_(lat_col, 'null').not_.is_(lon_col, 'null').execute()

            records = response.data
            total_with_coords = len(records)

            out_of_bounds = []

            for record in records:
                lat = float(record[lat_col])
                lon = float(record[lon_col])

                # ì„œìš¸ì‹œ ë²”ìœ„ ì²´í¬
                if not (SEOUL_BOUNDS['lat_min'] <= lat <= SEOUL_BOUNDS['lat_max'] and
                        SEOUL_BOUNDS['lon_min'] <= lon <= SEOUL_BOUNDS['lon_max']):
                    out_of_bounds.append({
                        'api_id': record['api_id'],
                        'lat': lat,
                        'lon': lon
                    })

            if out_of_bounds:
                print(f"  âš ï¸  ì„œìš¸ì‹œ ë²”ìœ„ ë²—ì–´ë‚¨: {len(out_of_bounds)}/{total_with_coords}ê°œ")

                self.issues.append({
                    'table': table,
                    'type': 'coordinate_bounds',
                    'count': len(out_of_bounds),
                    'total': total_with_coords,
                    'samples': out_of_bounds[:5]  # ìƒ˜í”Œ 5ê°œë§Œ
                })
            else:
                print(f"  âœ… ì¢Œí‘œ ë²”ìœ„: {total_with_coords}ê°œ ëª¨ë‘ ì •ìƒ")

        except Exception as e:
            print(f"  âš ï¸  ì¢Œí‘œ ê²€ì¦ ì‹¤íŒ¨: {e}")

    def _check_duplicates(self, table: str):
        """ì¤‘ë³µ ë ˆì½”ë“œ ê²€ì¦ (api_id ê¸°ì¤€)"""
        try:
            # api_idë³„ ì¹´ìš´íŠ¸
            response = supabase.table(table).select('api_id').execute()
            records = response.data

            api_ids = [r['api_id'] for r in records]
            unique_ids = set(api_ids)

            total = len(api_ids)
            unique = len(unique_ids)

            if total != unique:
                duplicates = total - unique
                print(f"  âš ï¸  ì¤‘ë³µ ë ˆì½”ë“œ: {duplicates}ê°œ (ì´ {total}ê°œ ì¤‘)")

                self.issues.append({
                    'table': table,
                    'type': 'duplicates',
                    'count': duplicates,
                    'total': total
                })
            else:
                print(f"  âœ… ì¤‘ë³µ ì—†ìŒ: {total}ê°œ ëª¨ë‘ ê³ ìœ ")

        except Exception as e:
            print(f"  âš ï¸  ì¤‘ë³µ ê²€ì¦ ì‹¤íŒ¨: {e}")

    def _check_missing_fields(self, table: str):
        """í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ê²€ì¦"""

        # í…Œì´ë¸”ë³„ í•„ìˆ˜ í•„ë“œ ì •ì˜
        required_fields = {
            'cultural_events': ['codename', 'title', 'strtdate'],
            'libraries': ['library_name', 'guname'],
            'cultural_spaces': ['fac_name', 'guname'],
            'future_heritages': ['name', 'main_category'],
            'public_reservations': ['svcnm', 'service_type']
        }

        if table not in required_fields:
            print(f"  âš ï¸  í•„ìˆ˜ í•„ë“œ ì •ì˜ ì—†ìŒ")
            return

        fields = required_fields[table]

        try:
            response = supabase.table(table).select('api_id,' + ','.join(fields)).execute()
            records = response.data

            missing_counts = {field: 0 for field in fields}

            for record in records:
                for field in fields:
                    if not record.get(field):
                        missing_counts[field] += 1

            # ëˆ„ë½ì´ ìˆëŠ” í•„ë“œë§Œ ì¶œë ¥
            has_missing = False
            for field, count in missing_counts.items():
                if count > 0:
                    has_missing = True
                    print(f"  âš ï¸  [{field}] ëˆ„ë½: {count}/{len(records)}ê°œ")

                    self.issues.append({
                        'table': table,
                        'type': 'missing_field',
                        'field': field,
                        'count': count,
                        'total': len(records)
                    })

            if not has_missing:
                print(f"  âœ… í•„ìˆ˜ í•„ë“œ: ëª¨ë‘ ì •ìƒ")

        except Exception as e:
            print(f"  âš ï¸  í•„ë“œ ê²€ì¦ ì‹¤íŒ¨: {e}")

    def _print_report(self):
        """ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸ“‹ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¦¬í¬íŠ¸")
        print("="*70)

        if not self.issues:
            print("\nâœ… ëª¨ë“  ê²€ì¦ í•­ëª© í†µê³¼! ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤.\n")
            return

        # ì´ìŠˆ íƒ€ì…ë³„ ë¶„ë¥˜
        issues_by_type = {}
        for issue in self.issues:
            issue_type = issue['type']
            if issue_type not in issues_by_type:
                issues_by_type[issue_type] = []
            issues_by_type[issue_type].append(issue)

        print(f"\nì´ ì´ìŠˆ: {len(self.issues)}ê°œ\n")

        # íƒ€ì…ë³„ ì¶œë ¥
        for issue_type, issues in issues_by_type.items():
            print(f"\nğŸ”´ {issue_type.upper()} ({len(issues)}ê°œ)")
            print("-" * 70)

            for issue in issues[:10]:  # ìµœëŒ€ 10ê°œë§Œ
                table = issue['table']

                if issue_type == 'coordinate_bounds':
                    print(f"  [{table}] ì„œìš¸ì‹œ ë²”ìœ„ ë²—ì–´ë‚¨: {issue['count']}/{issue['total']}ê°œ")
                    if issue.get('samples'):
                        for sample in issue['samples'][:3]:
                            print(f"    - api_id: {sample['api_id']}, "
                                  f"lat: {sample['lat']:.6f}, lon: {sample['lon']:.6f}")

                elif issue_type == 'duplicates':
                    print(f"  [{table}] ì¤‘ë³µ ë ˆì½”ë“œ: {issue['count']}ê°œ")

                elif issue_type == 'missing_field':
                    field = issue['field']
                    print(f"  [{table}] {field} ëˆ„ë½: {issue['count']}/{issue['total']}ê°œ")

                elif issue_type == 'error':
                    print(f"  [{table}] ì˜¤ë¥˜: {issue['message']}")

        print("\n" + "="*70 + "\n")

    def export_report(self, output_file: str = 'data_quality_report.txt'):
        """ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        report_path = Path('reports') / output_file
        report_path.parent.mkdir(exist_ok=True)

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¦¬í¬íŠ¸\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*70 + "\n\n")

            f.write(f"ì´ ì´ìŠˆ: {len(self.issues)}ê°œ\n\n")

            for issue in self.issues:
                f.write(f"[{issue['table']}] {issue['type']}\n")
                f.write(f"  {issue}\n\n")

        print(f"âœ… ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(
        description='Seoul Open API ë°ì´í„° í’ˆì§ˆ ê²€ì¦',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì „ì²´ í’ˆì§ˆ ê²€ì¦
  python data_quality_check.py

  # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
  python data_quality_check.py --export

  # íŠ¹ì • í…Œì´ë¸”ë§Œ ê²€ì¦
  python data_quality_check.py --table cultural_events
        """
    )

    parser.add_argument(
        '--export',
        action='store_true',
        help='ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥'
    )
    parser.add_argument(
        '--table',
        choices=[
            'cultural_events',
            'libraries',
            'cultural_spaces',
            'future_heritages',
            'public_reservations'
        ],
        help='íŠ¹ì • í…Œì´ë¸”ë§Œ ê²€ì¦'
    )

    args = parser.parse_args()

    checker = DataQualityChecker()

    # íŠ¹ì • í…Œì´ë¸”ë§Œ ê²€ì¦
    if args.table:
        checker.tables = [args.table]

    # ê²€ì¦ ì‹¤í–‰
    result = checker.check_all()

    # ë¦¬í¬íŠ¸ ì €ì¥
    if args.export:
        checker.export_report()

    # ì¢…ë£Œ ì½”ë“œ (ì´ìŠˆê°€ ìˆìœ¼ë©´ 1)
    sys.exit(1 if result['total_issues'] > 0 else 0)


if __name__ == "__main__":
    main()
