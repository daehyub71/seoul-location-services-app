"""
Seoul API ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
ì „ì²´ 9ê°œ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì†ŒëŸ‰ì˜ ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
from collectors.seoul_api_client import SeoulAPIClient
from app.utils.coordinate_transform import CoordinateTransformer

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)


async def collect_endpoint_sample(
    client: SeoulAPIClient,
    endpoint_key: str,
    max_records: int = 10
) -> Dict:
    """
    íŠ¹ì • ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘

    Args:
        client: SeoulAPIClient ì¸ìŠ¤í„´ìŠ¤
        endpoint_key: ì—”ë“œí¬ì¸íŠ¸ í‚¤ (ì˜ˆ: 'cultural_events')
        max_records: ìµœëŒ€ ìˆ˜ì§‘ ë ˆì½”ë“œ ìˆ˜

    Returns:
        {
            'endpoint_key': str,
            'endpoint_name': str,
            'total_count': int,
            'sample_count': int,
            'records': List[Dict],
            'collected_at': str
        }
    """
    endpoint_name = client.get_endpoint_name(endpoint_key)

    if not endpoint_name:
        logger.error(f"Unknown endpoint key: {endpoint_key}")
        return None

    try:
        logger.info(f"ğŸ” Collecting from {endpoint_key} ({endpoint_name})...")

        # ì´ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
        total_count = await client.get_total_count(endpoint_name)
        logger.info(f"   Total records: {total_count:,}")

        # ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘
        records = await client.fetch_all(endpoint_name, max_records=max_records)
        logger.info(f"   Collected: {len(records)} records")

        return {
            'endpoint_key': endpoint_key,
            'endpoint_name': endpoint_name,
            'total_count': total_count,
            'sample_count': len(records),
            'records': records,
            'collected_at': datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"âŒ Error collecting {endpoint_key}: {e}")
        return {
            'endpoint_key': endpoint_key,
            'endpoint_name': endpoint_name,
            'total_count': 0,
            'sample_count': 0,
            'records': [],
            'error': str(e),
            'collected_at': datetime.now().isoformat()
        }


def analyze_coordinates(records: List[Dict]) -> Dict:
    """
    ë ˆì½”ë“œì˜ ì¢Œí‘œ ë°ì´í„° ë¶„ì„

    Args:
        records: ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì¢Œí‘œ í†µê³„ ì •ë³´
    """
    transformer = CoordinateTransformer()

    total = len(records)
    with_coords = 0
    valid_coords = 0
    in_seoul = 0

    coord_fields = [
        ('LAT', 'LOT'),  # ëŒ€ë¶€ë¶„ì˜ API
        ('lat', 'lot'),  # ì†Œë¬¸ì
        ('XCNTS', 'YDNTS'),  # ì¼ë¶€ ì˜ˆì•½ API
        ('X', 'Y'),  # ê¸°íƒ€
    ]

    for record in records:
        # ì¢Œí‘œ í•„ë“œ ì°¾ê¸°
        lat, lon = None, None

        for lat_field, lon_field in coord_fields:
            if lat_field in record and lon_field in record:
                try:
                    lat = float(record[lat_field])
                    lon = float(record[lon_field])
                    with_coords += 1
                    break
                except (ValueError, TypeError):
                    continue

        if lat and lon:
            # ìœ íš¨ì„± ê²€ì¦
            if transformer.validate_wgs84(lat, lon):
                valid_coords += 1

                # ì„œìš¸ì‹œ ë²”ìœ„ í™•ì¸
                if transformer.is_in_seoul(lat, lon):
                    in_seoul += 1

    return {
        'total_records': total,
        'with_coordinates': with_coords,
        'valid_coordinates': valid_coords,
        'in_seoul': in_seoul,
        'coverage_rate': f"{with_coords/total*100:.1f}%" if total > 0 else "0%",
        'seoul_rate': f"{in_seoul/with_coords*100:.1f}%" if with_coords > 0 else "0%"
    }


async def collect_all_samples(max_records_per_endpoint: int = 10):
    """
    ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘

    Args:
        max_records_per_endpoint: ì—”ë“œí¬ì¸íŠ¸ë‹¹ ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜
    """
    api_key = os.getenv('SEOUL_API_KEY')

    if not api_key:
        logger.error("âŒ SEOUL_API_KEY not found in .env")
        return

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(__file__).parent.parent / 'data' / 'samples'
    output_dir.mkdir(parents=True, exist_ok=True)

    print("\n" + "="*70)
    print("Seoul API ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘")
    print("="*70)
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print(f"ì—”ë“œí¬ì¸íŠ¸ë‹¹ ìµœëŒ€ ë ˆì½”ë“œ: {max_records_per_endpoint}")
    print("="*70 + "\n")

    async with SeoulAPIClient(api_key) as client:
        endpoints = client.list_endpoints()

        print(f"ğŸ“Š ì´ {len(endpoints)}ê°œ ì—”ë“œí¬ì¸íŠ¸:\n")
        for key, name in endpoints.items():
            print(f"   - {key}: {name}")
        print()

        # ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        results = []

        for i, endpoint_key in enumerate(endpoints.keys(), 1):
            print(f"\n[{i}/{len(endpoints)}] {endpoint_key}")
            print("-" * 70)

            result = await collect_endpoint_sample(
                client,
                endpoint_key,
                max_records=max_records_per_endpoint
            )

            if result:
                results.append(result)

                # ê°œë³„ íŒŒì¼ ì €ì¥
                output_file = output_dir / f"{endpoint_key}_sample.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)

                logger.info(f"   âœ… Saved to {output_file.name}")

                # ì¢Œí‘œ ë¶„ì„
                if result['sample_count'] > 0:
                    coord_stats = analyze_coordinates(result['records'])
                    print(f"   ğŸ“ ì¢Œí‘œ í†µê³„:")
                    print(f"      - ì¢Œí‘œ í¬í•¨: {coord_stats['with_coordinates']}/{coord_stats['total_records']} ({coord_stats['coverage_rate']})")
                    print(f"      - ìœ íš¨ ì¢Œí‘œ: {coord_stats['valid_coordinates']}/{coord_stats['with_coordinates']}")
                    print(f"      - ì„œìš¸ì‹œ ë‚´: {coord_stats['in_seoul']}/{coord_stats['with_coordinates']} ({coord_stats['seoul_rate']})")

            # Rate limiting ë°©ì§€
            await asyncio.sleep(1)

        # ì „ì²´ ê²°ê³¼ ìš”ì•½ ì €ì¥
        summary = {
            'collected_at': datetime.now().isoformat(),
            'total_endpoints': len(endpoints),
            'successful': sum(1 for r in results if r.get('sample_count', 0) > 0),
            'failed': sum(1 for r in results if r.get('error')),
            'total_records': sum(r.get('sample_count', 0) for r in results),
            'endpoints': [
                {
                    'key': r['endpoint_key'],
                    'name': r['endpoint_name'],
                    'total_count': r['total_count'],
                    'sample_count': r['sample_count'],
                    'has_error': 'error' in r
                }
                for r in results
            ]
        }

        summary_file = output_dir / 'collection_summary.json'
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        # ìµœì¢… ìš”ì•½ ì¶œë ¥
        print("\n" + "="*70)
        print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
        print("="*70)
        print(f"ì´ ì—”ë“œí¬ì¸íŠ¸: {summary['total_endpoints']}")
        print(f"ì„±ê³µ: {summary['successful']}")
        print(f"ì‹¤íŒ¨: {summary['failed']}")
        print(f"ì´ ìˆ˜ì§‘ ë ˆì½”ë“œ: {summary['total_records']:,}")
        print(f"\nìš”ì•½ íŒŒì¼: {summary_file}")
        print("="*70 + "\n")

        # ìƒì„¸ í…Œì´ë¸” ì¶œë ¥
        print("\nì—”ë“œí¬ì¸íŠ¸ë³„ ìƒì„¸:")
        print("-" * 70)
        print(f"{'ì—”ë“œí¬ì¸íŠ¸':<30} {'ì „ì²´ ë ˆì½”ë“œ':>15} {'ìƒ˜í”Œ':>10} {'ìƒíƒœ':>10}")
        print("-" * 70)

        for endpoint in summary['endpoints']:
            status = "âŒ ì‹¤íŒ¨" if endpoint['has_error'] else "âœ… ì„±ê³µ"
            print(f"{endpoint['key']:<30} {endpoint['total_count']:>15,} {endpoint['sample_count']:>10} {status:>10}")

        print("-" * 70)

        return summary


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='Seoul API ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘')
    parser.add_argument(
        '--max-records',
        type=int,
        default=10,
        help='ì—”ë“œí¬ì¸íŠ¸ë‹¹ ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 10)'
    )
    parser.add_argument(
        '--endpoint',
        type=str,
        help='íŠ¹ì • ì—”ë“œí¬ì¸íŠ¸ë§Œ ìˆ˜ì§‘ (ì˜ˆ: cultural_events)'
    )

    args = parser.parse_args()

    if args.endpoint:
        # íŠ¹ì • ì—”ë“œí¬ì¸íŠ¸ë§Œ ìˆ˜ì§‘
        api_key = os.getenv('SEOUL_API_KEY')
        async with SeoulAPIClient(api_key) as client:
            result = await collect_endpoint_sample(
                client,
                args.endpoint,
                max_records=args.max_records
            )
            if result:
                print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        # ì „ì²´ ìˆ˜ì§‘
        await collect_all_samples(max_records_per_endpoint=args.max_records)


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    asyncio.run(main())
